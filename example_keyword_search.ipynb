{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example_keyword_search.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**How to perform a keyword search through a text file in Python** "
      ],
      "metadata": {
        "id": "IEy9d-GTOJtE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "konAmUO7N89Z"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install pandas\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import os, sys"
      ],
      "metadata": {
        "id": "NslqNc3NOSFN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keyword_search(file_name,search_values,indicator_name,save_name): \n",
        "    '''Function to perform a keyword search in a text file and get \n",
        "    counts / nanmean / failure counts \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "        file_name : string\n",
        "            name of text file with outputs in it \n",
        "        search_values : list\n",
        "            names of methods we are searching for in the file \n",
        "            one of the names must be the indicator of the block \n",
        "        indicator_name : string\n",
        "            name of the keyword that denotes a block in the text file \n",
        "            in JP's files, this is \"Info\" \n",
        "            we use to to determine which information is part of which run \n",
        "            \n",
        "    Returns\n",
        "    ----------\n",
        "        Pandas dataframe \n",
        "            two dataframes, one with nanmeans and failure counts for each method\n",
        "            one with re-formatted information from the text file \n",
        "    '''\n",
        "    options = search_values \n",
        "\n",
        "    collect_values = {} \n",
        "    for op in search_values: \n",
        "        collect_values[op] = [] \n",
        "\n",
        "    counts = {} \n",
        "    for op in search_values: \n",
        "        counts[op] = [] \n",
        "\n",
        "    count = 0\n",
        "    with open(file_name) as file:\n",
        "\n",
        "        for line in file:\n",
        "            \n",
        "            split_line = line.strip('\\n').split(':')\n",
        "            \n",
        "            for op in options:\n",
        "\n",
        "                if split_line[0] == op:\n",
        "\n",
        "                    if op == 'Info':\n",
        "\n",
        "                        collect_values[op].append(split_line[1][0:])\n",
        "                        if count == 0: \n",
        "                            counts[op].append(0)\n",
        "                        else:\n",
        "                            counts[op].append(counts[op][-1]+1)\n",
        "                        count+=1\n",
        "                    \n",
        "                    else: \n",
        "                        collect_values[op].append(int(split_line[1]))\n",
        "                        counts[op].append(counts['Info'][-1])\n",
        "\n",
        "        \n",
        "\n",
        "    file.close()\n",
        "\n",
        "    store_df = pd.DataFrame()\n",
        "\n",
        "    for op in options:\n",
        "\n",
        "        indices = counts[op]\n",
        "        \n",
        "        target_indices = list(range(0,len(counts[indicator_name])))\n",
        "        \n",
        "        collect_overwrite = [] \n",
        "        for i in target_indices:\n",
        "            if i in indices:\n",
        "                idx = indices.index(i)\n",
        "                collect_overwrite.append(collect_values[op][idx])\n",
        "            else:\n",
        "                collect_overwrite.append(np.nan) \n",
        "        \n",
        "        store_df[op] = collect_overwrite\n",
        "\n",
        "\n",
        "    averages = {}\n",
        "    failure_count = {} \n",
        "    for method in list(store_df):\n",
        "\n",
        "        if method != indicator_name: \n",
        "\n",
        "            averages[method] = np.nanmean(store_df[method])\n",
        "            failure_count[method] = store_df[method].isna().sum()  \n",
        "\n",
        "    average_df = pd.DataFrame(averages.items(), columns=['Method', 'Nan_Mean_'+save_name])\n",
        "    failure_df = pd.DataFrame(failure_count.items(), columns=['Method', 'Failure_Count'])\n",
        "    join_mean_failure = pd.concat([average_df, failure_df.reindex(average_df.index)], axis=1)\n",
        "    join_mean_failure = join_mean_failure.loc[:,~join_mean_failure.columns.duplicated()]\n",
        "\n",
        "    store_df.to_csv('counts_for_methods_'+save_name+'.txt',sep=',')\n",
        "    join_mean_failure.to_csv('join_mean_failure_'+save_name+'.txt',sep=',')\n",
        "\n",
        "    return store_df, join_mean_failure, average_df \n"
      ],
      "metadata": {
        "id": "_MpVv0NhOVGM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Connect to google drive to get the data. \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "607Vybw7Q6gp",
        "outputId": "ecddab6b-6d82-460a-96b1-58a752879e55"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Navigate to folder where data is stored in the drive. \n",
        "%cd /content/drive/MyDrive/jameslab/\n",
        "\n",
        "dirname = '/content/drive/MyDrive/jameslab/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM408RdhQ-n_",
        "outputId": "e00b4d18-bcac-4512-aeb4-9022d5bf847d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/jameslab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_lookup = ['Info','PCADAPT','PCADAPT q-values','PCADAPT Benjamini-Hochberg',\\\n",
        "               'PCADAPT Bonferroni','PCADAPT componentwise','OutFLANK qvalues',\\\n",
        "               'RDAadapt','LEA snfm/fst','LEA adjusted p-values','LEA lfmm/BH',\\\n",
        "               'LEA lfmm/non_adj','LEA lfmm2']\n",
        "target_file = 'CONCAT_outliers.txt'\n",
        "\n",
        "means = {} \n",
        "for fp in os.listdir(dirname+'JP/'):\n",
        "    df, jdf, mean_calc = keyword_search(dirname+'/JP/'+fp+'/CONCAT_outliers.txt',\\\n",
        "                                   keyword_lookup,'Info',fp)\n",
        "    \n",
        "    means[fp] = mean_calc\n",
        "    \n",
        "\n",
        "list_df = [x.set_index('Method') for x in means.values()]\n",
        "\n",
        "concat_means = pd.concat(list_df,axis=1, join='inner',\\\n",
        "                         names=means.keys()).reset_index()\n",
        "\n",
        "concat_means['Overall_Mean'] = concat_means.mean(axis=1)\n",
        "\n",
        "print(concat_means)\n",
        "\n",
        "concat_means.to_csv('means_for_methods_JP.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF_vKvjXQpoS",
        "outputId": "b511db03-99e8-4150-f285-b1d78e6d2b31"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        Method  Nan_Mean_8520  ...  Nan_Mean_8670  Overall_Mean\n",
            "0                      PCADAPT      11.060000  ...      10.640000     10.366667\n",
            "1             PCADAPT q-values      10.021277  ...       9.877551      9.784773\n",
            "2   PCADAPT Benjamini-Hochberg       9.744681  ...       9.714286      9.647778\n",
            "3           PCADAPT Bonferroni       5.978723  ...       6.326531      6.894703\n",
            "4        PCADAPT componentwise      27.042553  ...      23.836735     23.838833\n",
            "5             OutFLANK qvalues       0.127660  ...       0.166667      0.161525\n",
            "6                     RDAadapt       2.304348  ...       3.833333      5.877636\n",
            "7                 LEA snfm/fst       2.909091  ...       2.895833      2.988075\n",
            "8        LEA adjusted p-values       0.386364  ...       0.354167      0.659031\n",
            "9                  LEA lfmm/BH       2.590909  ...       1.770833      2.735789\n",
            "10            LEA lfmm/non_adj       0.681818  ...       0.291667      1.269958\n",
            "11                   LEA lfmm2       8.931818  ...       8.375000      7.946296\n",
            "\n",
            "[12 rows x 8 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ]
    }
  ]
}